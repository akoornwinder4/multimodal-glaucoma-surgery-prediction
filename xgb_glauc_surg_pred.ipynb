{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "amended-convertible",
   "metadata": {},
   "source": [
    "# XGBoost For Glaucoma Surgery Prediction\n",
    "Model construction, training, hyperparameter tuning, and evaluation for the XGBoost Fusion Model. The same process was applied for XGBoost single modality model training and evaluation as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "liable-monthly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# imports\n",
    "import sklearn \n",
    "import math \n",
    "import matplotlib.pyplot as plt\n",
    "import lazypredict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "from sklearn.model_selection import train_test_split\n",
    "from google.cloud import bigquery\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "central-parts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "thorough-league",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 tuning function\n",
    "def f1_tuning(test_pred,y_val):\n",
    "    f1scores={}\n",
    "    for i in np.arange(0.05,1.0,0.05):\n",
    "        new_pred = np.where(test_pred<i, 0 , 1)\n",
    "        f1scores[i]=f1_score(y_val,new_pred)\n",
    "        \n",
    "    return f1scores,max(f1scores, key=f1scores.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-suite",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "representative-visibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import single modality or fusion data \n",
    "\n",
    "# RNFL data\n",
    "rnfl_train = pd.read_csv('data/rnfl_train.csv')\n",
    "rnfl_val = pd.read_csv('data/rnfl_val.csv')\n",
    "rnfl_test = pd.read_csv('data/rnfl_test.csv')\n",
    "\n",
    "# Fusion data\n",
    "rnflehr_train = pd.read_csv('data/rnflehr_train.csv')\n",
    "rnflehr_val = pd.read_csv('data/rnflehr_val.csv')\n",
    "rnflehr_test = pd.read_csv('data/rnflehr_test.csv')\n",
    "\n",
    "# EHR data\n",
    "ehr_train = pd.read_csv('data/ehr_train.csv')\n",
    "ehr_val = pd.read_csv('data/ehr_val.csv')\n",
    "ehr_test = pd.read_csv('data/ehr_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "processed-nicholas",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = rnfl_train.drop(columns=['target', 'pat_mrn'])\n",
    "X_val = rnfl_val.drop(columns=['target', 'pat_mrn'])\n",
    "X_test = rnfl_test.drop(columns=['target', 'pat_mrn'])\n",
    "\n",
    "y_train = rnfl_train['target']\n",
    "y_val = rnfl_val['target']\n",
    "y_test = rnfl_test['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-passport",
   "metadata": {},
   "source": [
    "### XGB Fusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nervous-collection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep data\n",
    "X_train = rnflehr_train.drop(columns=['target', 'pat_mrn'])\n",
    "X_val = rnflehr_val.drop(columns=['target', 'pat_mrn'])\n",
    "X_test = rnflehr_test.drop(columns=['target', 'pat_mrn'])\n",
    "\n",
    "y_train = rnflehr_train['target']\n",
    "y_val = rnflehr_val['target']\n",
    "y_test = rnflehr_test['target']\n",
    "\n",
    "# Apply SMOTE to the training set to balance class distribution\n",
    "smote = SMOTE(random_state=42)  \n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Fit XGB \n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "xgb_clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "print(xgb_clf)\n",
    "\n",
    "expected_y  = y_val\n",
    "predicted_y = xgb_clf.predict(X_val)\n",
    "\n",
    "print(metrics.classification_report(expected_y, predicted_y))\n",
    "print(metrics.confusion_matrix(expected_y, predicted_y))\n",
    "\n",
    "print('Valid',roc_auc_score(expected_y,predicted_y))\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# Perform hyperparameter using the validation set\n",
    "grid_search_xgb = GridSearchCV(xgb_clf, param_grid_xgb, scoring='f1')\n",
    "grid_search_xgb.fit(X_val, y_val)\n",
    "\n",
    "best_xgb_model = grid_search_xgb.best_estimator_\n",
    "\n",
    "y_pred_xgb = best_xgb_model.predict(X_val)\n",
    "\n",
    "yval_probs_xgb = best_xgb_model.predict_proba(X_val)\n",
    "print('XGBoost validation roc-auc: ', roc_auc_score(y_val, yval_probs_xgb[:,1]))\n",
    "print()\n",
    "\n",
    "report_xgb = classification_report(y_val, y_pred_xgb)\n",
    "print(\"Classification Report for XGBoost on Validation Set:\")\n",
    "print(report_xgb)\n",
    "\n",
    "best_params_xgb = grid_search_xgb.best_params_\n",
    "print(\"Best Hyperparameters for XGBoost:\", best_params_xgb)\n",
    "\n",
    "# F1 thresholding \n",
    "best_threshold = 0.5  # Starting threshold\n",
    "\n",
    "best_f1_score = 0\n",
    "optimal_threshold = best_threshold\n",
    "\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    y_pred_thresholded = (yval_probs_xgb[:, 1] > threshold).astype(int)\n",
    "    f1 = f1_score(y_val, y_pred_thresholded)\n",
    "    \n",
    "    if f1 > best_f1_score:\n",
    "        best_f1_score = f1\n",
    "        optimal_threshold = threshold\n",
    "\n",
    "print(\"Optimal Threshold:\", optimal_threshold)\n",
    "print(\"Best F1 Score:\", best_f1_score)\n",
    "\n",
    "# Eval on test set\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "\n",
    "# XGBoost model\n",
    "model = best_xgb_model  # Replace with your XGBoost model\n",
    "model_name = \"XGBoost\"\n",
    "dataset_name = \"Fusion\"\n",
    "# optimal_threshold = optimal_t  # Replace with your optimal threshold\n",
    "\n",
    "# Predict probabilities for the positive class on the test set\n",
    "y_pred_probs_test = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_probs_test)\n",
    "\n",
    "# Generate classification report\n",
    "y_pred_thresholded = (y_pred_probs_test > optimal_threshold).astype(int)\n",
    "report = classification_report(y_test, y_pred_thresholded, digits=3)\n",
    "print(f\"Classification Report for {model_name} on {dataset_name} Test Set:\")\n",
    "print(report)\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_probs_test)\n",
    "\n",
    "# Plot ROC curve for the XGBoost model\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'Receiver Operating Characteristic - {model_name}')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "amateur-attack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models_updated/xgboost/xgboost_fusion_glauc_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "\n",
    "import joblib\n",
    "\n",
    "model = best_xgb_model  \n",
    "model_filename = 'models/xgboost/xgboost_fusion_glauc_model.pkl'\n",
    "joblib.dump(model, model_filename)\n",
    "\n",
    "print(f\"Model saved to {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-paste",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "r-cpu.3-6.mnightly-2021-02-12-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.3-6:mnightly-2021-02-12-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python [conda env:bert-pytorch]",
   "language": "python",
   "name": "conda-env-bert-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
